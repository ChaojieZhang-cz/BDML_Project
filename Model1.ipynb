{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "import openslide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "        transforms.Resize((1024,1024)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, df_path, train = False):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.train = train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        imgage_folder = '/scratch/cz2064/myjupyter/BDML/Project/data/'\n",
    "        file_id = self.df.iloc[idx]['File ID']\n",
    "        file_name = self.df.iloc[idx]['File Name']\n",
    "        image_path = imgage_folder+file_id+'/'+file_name\n",
    "        image = openslide.open_slide(image_path)\n",
    "        image = image.get_thumbnail((2048,2048))\n",
    "        image_tensor = image_transform(image)\n",
    "        image.close()\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        \n",
    "        sample = {'x': image_tensor, 'y': label}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = './train-Copy1.csv'\n",
    "val_df_path = './val-Copy1.csv'\n",
    "test_df_path = './test.csv'\n",
    "transformed_dataset = {'train': dataset(train_df_path, train = True),\n",
    "                       'validate':dataset(val_df_path),\n",
    "                       'test':dataset(test_df_path),}\n",
    "bs = 8\n",
    "dataloader = {x: DataLoader(transformed_dataset[x], batch_size=bs,\n",
    "                        shuffle=True, num_workers=0) for x in ['train', 'validate','test']}\n",
    "data_sizes ={x: len(transformed_dataset[x]) for x in ['train', 'validate','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = iter(dataset(train_df_path, train = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1024, 1024])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image['x'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_fn, num_epochs = 10, verbose = True, scheduler=None,\\\n",
    "                best_model_wts=None,best_acc=None):\n",
    "    acc_dict = {'train':[],'validate':[]}\n",
    "    loss_dict = {'train':[],'validate':[]}\n",
    "    if not best_acc:\n",
    "        best_acc = 0\n",
    "    phases = ['train','validate']\n",
    "    since = time.time()\n",
    "    for i in range(num_epochs):\n",
    "        print('Epoch: {}/{}'.format(i, num_epochs-1))\n",
    "        print('-'*10)\n",
    "        for p in phases:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if p == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            for data in dataloader[p]:\n",
    "                optimizer.zero_grad()\n",
    "                image = data['x'].to(device,dtype=torch.float)\n",
    "                label = data['y'].to(device,dtype=torch.long)\n",
    "                output = model(image)\n",
    "                loss = loss_fn(output, label)\n",
    "                print(loss)\n",
    "                _, preds = torch.max(output, dim = 1)\n",
    "                num_imgs = image.size()[0]\n",
    "                running_correct += torch.sum(preds ==label).item()\n",
    "                running_loss += loss.item()*num_imgs\n",
    "                running_total += num_imgs\n",
    "                if p== 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            epoch_acc = float(running_correct/running_total)\n",
    "            epoch_loss = float(running_loss/running_total)\n",
    "            if verbose or (i%10 == 0):\n",
    "                print('Phase:{}, epoch loss: {:.4f} Acc: {:.4f}'.format(p, epoch_loss, epoch_acc))\n",
    "            \n",
    "            acc_dict[p].append(epoch_acc)\n",
    "            loss_dict[p].append(epoch_loss)\n",
    "            if p == 'validate':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = model.state_dict()\n",
    "            else:\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "            torch.save({'epoch': i + 1,'state_dict': model.state_dict(),\\\n",
    "                        'best_model': best_model_wts,'best_acc':best_acc,\\\n",
    "                        'acc_dict':acc_dict,'loss_dict':loss_dict}, 'checkpoint.tar' )\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, acc_dict, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/49\n",
      "----------\n",
      "tensor(8.4821, grad_fn=<NllLossBackward>)\n",
      "tensor(4.2142, grad_fn=<NllLossBackward>)\n",
      "tensor(3.3328, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7961, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0554, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1949, grad_fn=<NllLossBackward>)\n",
      "tensor(4.8278, grad_fn=<NllLossBackward>)\n",
      "Phase:train, epoch loss: 3.5652 Acc: 0.2800\n",
      "tensor(1.5884, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4796, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9824, grad_fn=<NllLossBackward>)\n",
      "Phase:validate, epoch loss: 1.6048 Acc: 0.2105\n",
      "Epoch: 1/49\n",
      "----------\n",
      "tensor(1.1727, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, acc_dict, loss_dict = train_model(model, dataloader, optimizer, loss_fn, num_epochs = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
